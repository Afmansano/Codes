{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk; nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos também utilizar o spacy para isso, após instalá-lo, execute \"python3 -m spacy download en\" no terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos utilizar o dataset newsgroup, que possui aproximadamente 11 mil posts em 20 tópicos diferentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rec.autos' 'comp.sys.mac.hardware' 'rec.motorcycles' 'misc.forsale'\n",
      " 'comp.os.ms-windows.misc' 'alt.atheism' 'comp.graphics'\n",
      " 'rec.sport.baseball' 'rec.sport.hockey' 'sci.electronics' 'sci.space'\n",
      " 'talk.politics.misc' 'sci.med' 'talk.politics.mideast'\n",
      " 'soc.religion.christian' 'comp.windows.x' 'comp.sys.ibm.pc.hardware'\n",
      " 'talk.politics.guns' 'talk.religion.misc' 'sci.crypt']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>target</th>\n",
       "      <th>target_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>From: irwin@cmptrc.lonestar.org (Irwin Arnstei...</td>\n",
       "      <td>8</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>From: tchen@magnus.acs.ohio-state.edu (Tsung-K...</td>\n",
       "      <td>6</td>\n",
       "      <td>misc.forsale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>From: dabl2@nlm.nih.gov (Don A.B. Lindbergh)\\n...</td>\n",
       "      <td>2</td>\n",
       "      <td>comp.os.ms-windows.misc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content  target  \\\n",
       "0     From: lerxst@wam.umd.edu (where's my thing)\\nS...       7   \n",
       "1     From: guykuo@carson.u.washington.edu (Guy Kuo)...       4   \n",
       "10    From: irwin@cmptrc.lonestar.org (Irwin Arnstei...       8   \n",
       "100   From: tchen@magnus.acs.ohio-state.edu (Tsung-K...       6   \n",
       "1000  From: dabl2@nlm.nih.gov (Don A.B. Lindbergh)\\n...       2   \n",
       "\n",
       "                 target_names  \n",
       "0                   rec.autos  \n",
       "1       comp.sys.mac.hardware  \n",
       "10            rec.motorcycles  \n",
       "100              misc.forsale  \n",
       "1000  comp.os.ms-windows.misc  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('https://raw.githubusercontent.com/selva86/datasets/master/newsgroups.json')\n",
    "print(df.target_names.unique())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = df.content.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos iniciar o preprocessamenot de dados removendo endereços de e-mail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = [re.sub('\\S*@\\S*\\s?', ' ', sent) for sent in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removendo linhas em branco e quebras de linha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = [re.sub('\\s+', ' ', sent) for sent in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removendo aspas simples (de it's, he's ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = [re.sub(\"\\'\", \"\", sent) for sent in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo podemos visualizar as alterações feitas. No primeiro bloco o texto antes de ser pré processado e no segundo após pré processar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"From: lerxst@wam.umd.edu (where's my thing)\\n\"\n",
      " 'Subject: WHAT car is this!?\\n'\n",
      " 'Nntp-Posting-Host: rac3.wam.umd.edu\\n'\n",
      " 'Organization: University of Maryland, College Park\\n'\n",
      " 'Lines: 15\\n'\n",
      " '\\n'\n",
      " ' I was wondering if anyone out there could enlighten me on this car I saw\\n'\n",
      " 'the other day. It was a 2-door sports car, looked to be from the late 60s/\\n'\n",
      " 'early 70s. It was called a Bricklin. The doors were really small. In '\n",
      " 'addition,\\n'\n",
      " 'the front bumper was separate from the rest of the body. This is \\n'\n",
      " 'all I know. If anyone can tellme a model name, engine specs, years\\n'\n",
      " 'of production, where this car is made, history, or whatever info you\\n'\n",
      " 'have on this funky looking car, please e-mail.\\n'\n",
      " '\\n'\n",
      " 'Thanks,\\n'\n",
      " '- IL\\n'\n",
      " '   ---- brought to you by your neighborhood Lerxst ----\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n')\n"
     ]
    }
   ],
   "source": [
    "pprint(df.content[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['From: (wheres my thing) Subject: WHAT car is this!? Nntp-Posting-Host: '\n",
      " 'rac3.wam.umd.edu Organization: University of Maryland, College Park Lines: '\n",
      " '15 I was wondering if anyone out there could enlighten me on this car I saw '\n",
      " 'the other day. It was a 2-door sports car, looked to be from the late 60s/ '\n",
      " 'early 70s. It was called a Bricklin. The doors were really small. In '\n",
      " 'addition, the front bumper was separate from the rest of the body. This is '\n",
      " 'all I know. If anyone can tellme a model name, engine specs, years of '\n",
      " 'production, where this car is made, history, or whatever info you have on '\n",
      " 'this funky looking car, please e-mail. Thanks, - IL ---- brought to you by '\n",
      " 'your neighborhood Lerxst ---- ']\n"
     ]
    }
   ],
   "source": [
    "pprint(data[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embora tenhamos limpado um pouco nosso texto, ele ainda está um pouco sujo, com símbolos, pontuações e outros caracteres desnecessários para executarmos o LDA. O método simple_preprocess do Gensim nos auxilia nesse tipo de limpeza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_words = list(sent_to_words(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['from', 'wheres', 'my', 'thing', 'subject', 'what', 'car', 'is', 'this', 'nntp', 'posting', 'host', 'rac', 'wam', 'umd', 'edu', 'organization', 'university', 'of', 'maryland', 'college', 'park', 'lines', 'was', 'wondering', 'if', 'anyone', 'out', 'there', 'could', 'enlighten', 'me', 'on', 'this', 'car', 'saw', 'the', 'other', 'day', 'it', 'was', 'door', 'sports', 'car', 'looked', 'to', 'be', 'from', 'the', 'late', 'early', 'it', 'was', 'called', 'bricklin', 'the', 'doors', 'were', 'really', 'small', 'in', 'addition', 'the', 'front', 'bumper', 'was', 'separate', 'from', 'the', 'rest', 'of', 'the', 'body', 'this', 'is', 'all', 'know', 'if', 'anyone', 'can', 'tellme', 'model', 'name', 'engine', 'specs', 'years', 'of', 'production', 'where', 'this', 'car', 'is', 'made', 'history', 'or', 'whatever', 'info', 'you', 'have', 'on', 'this', 'funky', 'looking', 'car', 'please', 'mail', 'thanks', 'il', 'brought', 'to', 'you', 'by', 'your', 'neighborhood', 'lerxst']\n"
     ]
    }
   ],
   "source": [
    "print(data_words[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Gensim também nos fornece ferramentas para crias bigramas e trigramas de palavras que aparecem frequentemente juntas https://radimrehurek.com/gensim/models/phrases.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexmansano/anaconda/lib/python3.6/site-packages/gensim/models/phrases.py:494: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    }
   ],
   "source": [
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100)\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após \"treinado\" nosso detector de frases, podemos utlizar Phraser para transformar as sentenças"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['from', 'wheres', 'my', 'thing', 'subject', 'what', 'car', 'is', 'this', 'nntp_posting', 'host', 'rac_wam', 'umd_edu', 'organization', 'university', 'of', 'maryland_college', 'park', 'lines', 'was', 'wondering', 'if', 'anyone', 'out', 'there', 'could', 'enlighten', 'me', 'on', 'this', 'car', 'saw', 'the', 'other', 'day', 'it', 'was', 'door', 'sports', 'car', 'looked', 'to', 'be', 'from', 'the', 'late', 'early', 'it', 'was', 'called', 'bricklin', 'the', 'doors', 'were', 'really', 'small', 'in', 'addition', 'the', 'front_bumper', 'was', 'separate', 'from', 'the', 'rest', 'of', 'the', 'body', 'this', 'is', 'all', 'know', 'if', 'anyone', 'can', 'tellme', 'model', 'name', 'engine', 'specs', 'years', 'of', 'production', 'where', 'this', 'car', 'is', 'made', 'history', 'or', 'whatever', 'info', 'you', 'have', 'on', 'this', 'funky', 'looking', 'car', 'please', 'mail', 'thanks', 'il', 'brought', 'to', 'you', 'by', 'your', 'neighborhood', 'lerxst']\n"
     ]
    }
   ],
   "source": [
    "print(bigram_mod[data_words[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['from', 'wheres', 'my', 'thing', 'subject', 'what', 'car', 'is', 'this', 'nntp_posting_host', 'rac_wam_umd_edu', 'organization', 'university', 'of', 'maryland_college_park', 'lines', 'was', 'wondering', 'if', 'anyone', 'out', 'there', 'could', 'enlighten', 'me', 'on', 'this', 'car', 'saw', 'the', 'other', 'day', 'it', 'was', 'door', 'sports', 'car', 'looked', 'to', 'be', 'from', 'the', 'late', 'early', 'it', 'was', 'called', 'bricklin', 'the', 'doors', 'were', 'really', 'small', 'in', 'addition', 'the', 'front_bumper', 'was', 'separate', 'from', 'the', 'rest', 'of', 'the', 'body', 'this', 'is', 'all', 'know', 'if', 'anyone', 'can', 'tellme', 'model', 'name', 'engine', 'specs', 'years', 'of', 'production', 'where', 'this', 'car', 'is', 'made', 'history', 'or', 'whatever', 'info', 'you', 'have', 'on', 'this', 'funky', 'looking', 'car', 'please', 'mail', 'thanks', 'il', 'brought', 'to', 'you', 'by', 'your', 'neighborhood', 'lerxst']\n"
     ]
    }
   ],
   "source": [
    "print(trigram_mod[bigram_mod[data_words[0]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que temos um modelo de bigramas, vamos remover as stopwords. Stopwords são palavras que aparecem com muita frequência no vocabulário e não agregam muita informação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(texts):\n",
    "    return [\n",
    "        [word for word in simple_preprocess(str(doc)) if word not in stop_words]\n",
    "        for doc in texts\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lemmatization(texts, allowed_postags=['NOUN', 'AJD', 'VERB', 'ADV']):\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent))\n",
    "        texts_out.append([token.lemma_ for token in doc \n",
    "                         if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_words_nostops = remove_stopwords(data_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_words_bigrams = make_bigrams(data_words_nostops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en', disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_lemmatized = lemmatization(data_words_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['where', 's', 'thing', 'car', 'nntp_post', 'host', 'rac_wam', 'organization', 'university', 'maryland_college', 'park', 'line', 'wonder', 'anyone', 'could', 'enlighten', 'car', 'see', 'day', 'door', 'sport', 'car', 'look', 'late', 'early', 'call', 'bricklin', 'door', 'really', 'addition', 'rest', 'body', 'know', 'anyone', 'model', 'name', 'engine', 'spec', 'year', 'production', 'car', 'make', 'history', 'info', 'funky', 'look', 'car', 'mail', 'thank', 'bring', 'neighborhood', 'lerxst']\n"
     ]
    }
   ],
   "source": [
    "print(data_lemmatized[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma vez que processamos os dados, vamos criar os dicionário e corpus necessários para iniciar nosso Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id2word = corpora.Dictionary(data_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts = data_lemmatized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aqui, corpus é nosso Term Document Frequency, ou seja, uma tabela/lista com cada token e o numero de ocorrencias dele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar a frequencia de cada token nos nossos documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 2), (2, 1), (3, 1), (4, 1), (5, 1), (6, 5), (7, 1), (8, 1), (9, 2), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 2), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1)]\n"
     ]
    }
   ],
   "source": [
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('addition', 1), ('anyone', 2), ('body', 1), ('bricklin', 1), ('bring', 1), ('call', 1), ('car', 5), ('could', 1), ('day', 1), ('door', 2), ('early', 1), ('engine', 1), ('enlighten', 1), ('funky', 1), ('history', 1), ('host', 1), ('info', 1), ('know', 1), ('late', 1), ('lerxst', 1), ('line', 1), ('look', 2), ('mail', 1), ('make', 1), ('maryland_college', 1), ('model', 1), ('name', 1), ('neighborhood', 1), ('nntp_post', 1), ('organization', 1), ('park', 1), ('production', 1), ('rac_wam', 1), ('really', 1), ('rest', 1), ('s', 1), ('see', 1), ('spec', 1), ('sport', 1), ('thank', 1), ('thing', 1), ('university', 1), ('where', 1), ('wonder', 1), ('year', 1)]\n"
     ]
    }
   ],
   "source": [
    "bow_names = [(id2word[index], count) for index, count in corpus[0]]\n",
    "print(bow_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos construir nosso modelo, para isso temos que observar alguns parâmetros: \n",
    "<ul>\n",
    "    <li><b>chunksize</b>: número de documentos utilizados em cada bloco de treinamento </li>\n",
    "    <li><b>update_every</b>: com que freqência os parâmetros do modelo serão atualizados</li>\n",
    "    <li><b>passes</b>: quantas iterações serão executadas</li>\n",
    "    <li><b>alpha</b> e <b>eta</b>: parâmetros que controlam a esparsidade dos tópicos</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                            id2word=id2word,\n",
    "                                            num_topics=20,\n",
    "                                            random_state=100,\n",
    "                                            update_every=1,\n",
    "                                            chunksize=100,\n",
    "                                            passes=10,\n",
    "                                            alpha='auto',\n",
    "                                            per_word_topics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo criado é constituído de 20 tópicos distintos, onde cada tópico é composto pela combinação de palavras-chave e cada uma delas contribui com uma certa proporção ao tópico "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos visualizar essas palavras e a contribuição delas para cada tópico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que o tópico 0 é representado 0.018 por \"disk\", 0.017 por \"monitor\", 0.017 por \"machine\", 0.016 por \"mac\", ... , 0.013 por \"pc\". Podemos assumir que se trata de um tópico sobre especificação de computadores. Enquanto o tópico 17 é 0.025 por \"gun\", 0.020 por \"government\", 0.016 por \"armenian\", 0.015 por \"people\", 0.012 por \"war\", 0.010 por \"kill\" ... tratando-se de um tópico de política/conflitos políticos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos aferir o quão bem o modelo está gerando os tópicos calculando a perplexidade (como as probabilidades preditas estão distribuídas, relacionado à entropia, ou seja $2^{E(t)}$) ou por meio da coerência dos tópicos https://rare-technologies.com/what-is-topic-coherence/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos avaliar a perplexidade. Quanto menor o valor, melhor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model.log_perplexity((corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos calcular a coerência. Quanto maior melhor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_model_lda = CoherenceModel(model=lda_model, \n",
    "                                     texts=data_lemmatized, \n",
    "                                     dictionary=id2word,\n",
    "                                     coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "coherence_lda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Visualizando os tópicos</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma vez que o modelo foi criado, o próximo passo é examinar os tópicos gerados e as palavras associadas e eles. Vamos utilizar o pacote pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pyLDAvis.show(vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada círculo em nosso gráfico representa um tópico. Quanto maior, mais dominante ele é. Um bom modelo possui círculos grandes e com poucas sobreposições/intersecções distribuídos pelo gráfico (não apenas concentrados em um único quadrante). <br>\n",
    "Se o modelo possuir tópicos em excesso, os círculos serão pequenos e com muitas sobreposições agrupados em uma região do gráfico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O algoritmo LDA Mallet apresenta melhores resultados que o default do gensim. Para usa-lo devemos baixar o bin no link http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip e chamá-lo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mallet_path = 'mallet-2.0.8/bin/mallet' # alterar esse caminho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, \n",
    "                                            corpus=corpus, \n",
    "                                            num_topics=20, \n",
    "                                            id2word=id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(16,\n",
      "  [('question', 0.018697772088541141),\n",
      "   ('make', 0.017345779337523553),\n",
      "   ('people', 0.015835574668833691),\n",
      "   ('thing', 0.014469199016209531),\n",
      "   ('point', 0.014109626476045278),\n",
      "   ('reason', 0.013620607821421894),\n",
      "   ('exist', 0.013002143052339378),\n",
      "   ('write', 0.011434406777223237),\n",
      "   ('argument', 0.010787176204927583),\n",
      "   ('claim', 0.01037007205833705)]),\n",
      " (19,\n",
      "  [('line', 0.1183433242506812),\n",
      "   ('organization', 0.11407084468664851),\n",
      "   ('nntp_post', 0.10107901907356948),\n",
      "   ('host', 0.090746594005449585),\n",
      "   ('write', 0.088261580381471388),\n",
      "   ('article', 0.071411444141689373),\n",
      "   ('university', 0.047389645776566756),\n",
      "   ('reply', 0.04017438692098093),\n",
      "   ('distribution_world', 0.015694822888283378),\n",
      "   ('usa', 0.014103542234332425)]),\n",
      " (10,\n",
      "  [('space', 0.02754044719141974),\n",
      "   ('year', 0.0095437193237593171),\n",
      "   ('system', 0.0087256862388656615),\n",
      "   ('launch', 0.0083075804399200138),\n",
      "   ('project', 0.0079985457189601893),\n",
      "   ('earth', 0.0078349391019814571),\n",
      "   ('cost', 0.0076895109980003639),\n",
      "   ('satellite', 0.0063988365751681516),\n",
      "   ('research', 0.0061625159061988732),\n",
      "   ('datum', 0.0061079803672059625)]),\n",
      " (9,\n",
      "  [('ax', 0.85972214080543996),\n",
      "   ('max', 0.063075209566797588),\n",
      "   ('tm', 0.0021982531215194324),\n",
      "   ('qax', 0.002051702913418137),\n",
      "   ('_', 0.0011870566856204937),\n",
      "   ('mf', 0.0010698165191394572),\n",
      "   ('gq', 0.00080602614455712522),\n",
      "   ('giz', 0.00079137112374699575),\n",
      "   ('fp', 0.00076206108212673658),\n",
      "   ('wm_wm', 0.00074740606131660711)]),\n",
      " (18,\n",
      "  [('people', 0.014329506085505433),\n",
      "   ('world', 0.011735684097875967),\n",
      "   ('war', 0.0097948522609783966),\n",
      "   ('history', 0.0094502185703143424),\n",
      "   ('armenian', 0.0091418621102465035),\n",
      "   ('turk', 0.0064029312002321743),\n",
      "   ('today', 0.0064029312002321743),\n",
      "   ('government', 0.0062578222778473091),\n",
      "   ('number', 0.0060764361248662278),\n",
      "   ('force', 0.005949465817779471)]),\n",
      " (6,\n",
      "  [('write', 0.051249633124873004),\n",
      "   ('article', 0.045176438714921094),\n",
      "   ('organization', 0.038945205788725082),\n",
      "   ('line', 0.035874743187411101),\n",
      "   ('bike', 0.015826428555302193),\n",
      "   ('make', 0.014020274083941029),\n",
      "   ('thing', 0.0093468493892940197),\n",
      "   ('dod', 0.0084663490845054527),\n",
      "   ('ride', 0.0067505023367123475),\n",
      "   ('opinion', 0.0065698868895762309)]),\n",
      " (1,\n",
      "  [('card', 0.022550340970811288),\n",
      "   ('computer', 0.018627667920580959),\n",
      "   ('line', 0.018366156383898935),\n",
      "   ('sale', 0.01802417975900706),\n",
      "   ('mac', 0.015268250487819598),\n",
      "   ('organization', 0.015006738951137575),\n",
      "   ('monitor', 0.013196274466415884),\n",
      "   ('price', 0.01317615819436342),\n",
      "   ('apple', 0.012270925952002574),\n",
      "   ('board', 0.011063949628854781)]),\n",
      " (5,\n",
      "  [('window', 0.041852275728497229),\n",
      "   ('drive', 0.027801743111189364),\n",
      "   ('problem', 0.025829738533321597),\n",
      "   ('run', 0.018980544061977286),\n",
      "   ('driver', 0.014842855885201163),\n",
      "   ('system', 0.014208997270886523),\n",
      "   ('work', 0.01278281538867858),\n",
      "   ('set', 0.010722774892155999),\n",
      "   ('disk', 0.010159345012765207),\n",
      "   ('mode', 0.0093494145611409448)]),\n",
      " (2,\n",
      "  [('_', 0.041066405772288123),\n",
      "   ('food', 0.0086339733398556936),\n",
      "   ('disease', 0.0077779136602666018),\n",
      "   ('doctor', 0.0072887367005014065),\n",
      "   ('gordon_bank', 0.0065305124128653544),\n",
      "   ('patient', 0.0063348416289592761),\n",
      "   ('msg', 0.0059679589091353796),\n",
      "   ('eat', 0.0058945823651706001),\n",
      "   ('study', 0.0053809465574171456),\n",
      "   ('treatment', 0.0053564877094288855)]),\n",
      " (11,\n",
      "  [('write', 0.019760237562781831),\n",
      "   ('people', 0.012703009861788319),\n",
      "   ('state', 0.010979946475052241),\n",
      "   ('article', 0.010723320013197932),\n",
      "   ('make', 0.0085236646258752789),\n",
      "   ('israel', 0.0081937163177768814),\n",
      "   ('kill', 0.0079004289328005271),\n",
      "   ('opinion', 0.0076987938556292851),\n",
      "   ('fire', 0.0069289144700663561),\n",
      "   ('fact', 0.0064889833926018254)])]\n"
     ]
    }
   ],
   "source": [
    "pprint(ldamallet.show_topics(formatted=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62520198782615322"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherence_model_ldamallet = CoherenceModel(model=ldamallet, \n",
    "                                           texts=data_lemmatized, \n",
    "                                           dictionary=id2word, \n",
    "                                           coherence='c_v')\n",
    "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
    "coherence_ldamallet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Escolhendo o número de Tópicos</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No processo convencional de agrupamento (k-means, EM...) quando estamos procurando o número de grupos geramos vários modelos variando o valor de k (número de grupos) e plotamos curvas para analisar o comportamento dos grupos em cada caso (elbow, silhoueta). <br>\n",
    "Para problemas de Topic Modeling podemos seguir uma abordagem muito similar, acompanhando o valor de coerência obtido por cada modelo. Podemos escolher k como o valor que apresenta o maior aumento de coerência se comparado ao valor menor imediatamente anterior. Também é importante notar se há muitas repetições de palavras em tópicos distintos. Isso pode indicar que o valor de k está muito alto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for k in range(start, limit, step):\n",
    "        print('Fitting LDA with '+ str(k)+ ' groups...')\n",
    "        model = gensim.models.wrappers.LdaMallet(mallet_path, \n",
    "                                                 corpus=corpus, \n",
    "                                                 num_topics=k, \n",
    "                                                 id2word=id2word)\n",
    "        model_list.append(model)\n",
    "        coherence_model = CoherenceModel(model=model, \n",
    "                                         texts=texts,\n",
    "                                         dictionary=dictionary,\n",
    "                                         coherence='c_v')\n",
    "        coherence_values.append(coherence_model.get_coherence())    \n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting LDA with 2 groups...\n",
      "Fitting LDA with 8 groups...\n",
      "Fitting LDA with 14 groups...\n",
      "Fitting LDA with 20 groups...\n",
      "Fitting LDA with 26 groups...\n",
      "Fitting LDA with 32 groups...\n",
      "Fitting LDA with 38 groups...\n"
     ]
    }
   ],
   "source": [
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, \n",
    "                                                        corpus=corpus, \n",
    "                                                        texts=data_lemmatized, \n",
    "                                                        start=2, \n",
    "                                                        limit=40, \n",
    "                                                        step=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nE4mZmXWIE4mZmXWIE4mZmXXI/w8wHr+UpZ/4QAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1564d3828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "limit=40; start=2; step=6;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Topics = 2  has Coherence Value of 0.4667\n",
      "Num Topics = 8  has Coherence Value of 0.5967\n",
      "Num Topics = 14  has Coherence Value of 0.6285\n",
      "Num Topics = 20  has Coherence Value of 0.6419\n",
      "Num Topics = 26  has Coherence Value of 0.6409\n",
      "Num Topics = 32  has Coherence Value of 0.6512\n",
      "Num Topics = 38  has Coherence Value of 0.6448\n"
     ]
    }
   ],
   "source": [
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim como quando utilizamos o elbow, é recomendado escolhermos o numero k antes que a evolução se torne linear, que é o que acontece com k=20. Ou seja, nosso número ótimo de k seria 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos agora encontrar o tópico dominante em cada sentença"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimal_model = model_list[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_topics_sentences(ldamodel, corpus=corpus, texts=data):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, \n",
    "                                                  corpus=corpus, \n",
    "                                                  texts=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.1929</td>\n",
       "      <td>car, write, article, line, organization, bike,...</td>\n",
       "      <td>From: (wheres my thing) Subject: WHAT car is t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.2367</td>\n",
       "      <td>drive, system, card, mac, problem, bit, monito...</td>\n",
       "      <td>From: (Guy Kuo) Subject: SI Clock Poll - Final...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.2935</td>\n",
       "      <td>car, write, article, line, organization, bike,...</td>\n",
       "      <td>From: (Irwin Arnstein) Subject: Re: Recommenda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.3354</td>\n",
       "      <td>server, version, window, application, include,...</td>\n",
       "      <td>From: (Tsung-Kun Chen) Subject: ** Software fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.2570</td>\n",
       "      <td>window, line, file, problem, run, driver, orga...</td>\n",
       "      <td>From: (Don A.B. Lindbergh) Subject: Diamond SS...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0            0            19.0              0.1929   \n",
       "1            1             7.0              0.2367   \n",
       "2            2            19.0              0.2935   \n",
       "3            3            10.0              0.3354   \n",
       "4            4             5.0              0.2570   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  car, write, article, line, organization, bike,...   \n",
       "1  drive, system, card, mac, problem, bit, monito...   \n",
       "2  car, write, article, line, organization, bike,...   \n",
       "3  server, version, window, application, include,...   \n",
       "4  window, line, file, problem, run, driver, orga...   \n",
       "\n",
       "                                                Text  \n",
       "0  From: (wheres my thing) Subject: WHAT car is t...  \n",
       "1  From: (Guy Kuo) Subject: SI Clock Poll - Final...  \n",
       "2  From: (Irwin Arnstein) Subject: Re: Recommenda...  \n",
       "3  From: (Tsung-Kun Chen) Subject: ** Software fo...  \n",
       "4  From: (Don A.B. Lindbergh) Subject: Diamond SS...  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dominant_topic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
