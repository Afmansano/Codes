{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.contrib.layers import fully_connected\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_init = tf.contrib.layers.variance_scaling_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dnn_layers(inputs, name=\"dnn\", n_neurons=100):\n",
    "    with tf.variable_scope(name):\n",
    "        for layer in range(5):\n",
    "            inputs = fully_connected(inputs, n_neurons, \n",
    "                                     activation_fn=tf.nn.elu,\n",
    "                                     weights_initializer=he_init,\n",
    "                                     scope=\"hidden%d\" % (layer+1))\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos criar um placeholder para armazenar cada par de imagens, depois utilizamos a função untack para separá-los. Assim a entrada do nosso código fica mais transparente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 28*28\n",
    "\n",
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(tf.float32, shape=(None, 2, n_inputs), name=\"X\")\n",
    "X1, X2 = tf.unstack(X, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precisamos de um placeholder para nossas labels, que serão 0 se o par de imagens for diferente e 1 se elas forem iguais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.placeholder(tf.int32, shape=[None, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn1 = get_dnn_layers(X1, name=\"DNN_A\")\n",
    "dnn2 = get_dnn_layers(X2, name=\"DNN_B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos concatenar a saída das duas redes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_outputs = tf.concat([dnn1, dnn2], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada DNN tem 100 neurônios de saída, então a DNN final terá 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(100)])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(100)])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(200)])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos adicionar uma camada com 10 neurônios acima destas duas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = fully_connected(dnn_outputs, 10, activation_fn=tf.nn.elu, weights_initializer=he_init)\n",
    "logits = fully_connected(hidden, 1, activation_fn=None, weights_initializer=he_init)\n",
    "y_proba = tf.nn.sigmoid(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A rede neural prediz 1 se y_proba >=0.5. Nós utilizamos 1 se logits>=0, o que nos fornece o mesmo resultado, porém é calculado de maneira mais rápida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tf.cast(tf.greater_equal(logits, 0), tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_as_float = tf.cast(y, tf.float32)\n",
    "xentropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_as_float, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "momentum = 0.95\n",
    "\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate, momentum, use_nesterov=True)\n",
    "training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_correct = tf.equal(y_pred, y)\n",
    "accuracy = tf.reduce_mean(tf.cast(y_pred_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = mnist.train.images\n",
    "y_train1 = mnist.train.labels\n",
    "\n",
    "X_train2 = mnist.validation.images\n",
    "y_train2 = mnist.validation.labels\n",
    "\n",
    "X_test = mnist.test.images\n",
    "y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos escrever uma função para gerar pares de imagens, sendo 50% da mesma classe e 50% de classes distintas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(images, labels, batch_size):\n",
    "    size1 = batch_size // 2\n",
    "    size2 = batch_size - size1\n",
    "    if size1 != size2 and np.random.rand() > 0.5:\n",
    "        size1, size2 = size2, size1\n",
    "    X = []\n",
    "    y = []\n",
    "    while len(X) < size1:\n",
    "        rnd_idx1, rnd_idx2 = np.random.randint(0, len(images), 2)\n",
    "        if rnd_idx1 != rnd_idx2 and labels[rnd_idx1] == labels[rnd_idx2]:\n",
    "            X.append(np.array([images[rnd_idx1], images[rnd_idx2]]))\n",
    "            y.append([1])\n",
    "    while len(X) < batch_size:\n",
    "        rnd_idx1, rnd_idx2 = np.random.randint(0, len(images), 2)\n",
    "        if labels[rnd_idx1] != labels[rnd_idx2]:\n",
    "            X.append(np.array([images[rnd_idx1], images[rnd_idx2]]))\n",
    "            y.append([0])\n",
    "    rnd_indices = np.random.permutation(batch_size)\n",
    "    return np.array(X)[rnd_indices], np.array(y)[rnd_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vamos gerar um batch de exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "X_batch, y_batch = generate_batch(X_train1, y_train1, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5, 2, 784), dtype('float32'))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch.shape, X_batch.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANMAAAGfCAYAAADF6ud6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12193cba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(3, 3 * batch_size))\n",
    "plt.subplot(121)\n",
    "plt.imshow(X_batch[:,0].reshape(28 * batch_size, 28), cmap=\"binary\", interpolation=\"nearest\")\n",
    "plt.axis('off')\n",
    "plt.subplot(122)\n",
    "plt.imshow(X_batch[:,1].reshape(28 * batch_size, 28), cmap=\"binary\", interpolation=\"nearest\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos treinar nossa rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test1, y_test1 = generate_batch(X_test, y_test, batch_size=len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train loss: 0.451689\n",
      "0 Test accuracy: 0.7604\n",
      "1 Train loss: 0.409759\n",
      "2 Train loss: 0.329544\n",
      "3 Train loss: 0.251561\n",
      "4 Train loss: 0.253576\n",
      "5 Train loss: 0.240913\n",
      "5 Test accuracy: 0.908\n",
      "6 Train loss: 0.194647\n",
      "7 Train loss: 0.2049\n",
      "8 Train loss: 0.162026\n",
      "9 Train loss: 0.192288\n",
      "10 Train loss: 0.180107\n",
      "10 Test accuracy: 0.9345\n",
      "11 Train loss: 0.147522\n",
      "12 Train loss: 0.125812\n",
      "13 Train loss: 0.141168\n",
      "14 Train loss: 0.201941\n",
      "15 Train loss: 0.113482\n",
      "15 Test accuracy: 0.9457\n",
      "16 Train loss: 0.181659\n",
      "17 Train loss: 0.101065\n",
      "18 Train loss: 0.122983\n",
      "19 Train loss: 0.10227\n",
      "20 Train loss: 0.122218\n",
      "20 Test accuracy: 0.9538\n",
      "21 Train loss: 0.119919\n",
      "22 Train loss: 0.110726\n",
      "23 Train loss: 0.0623851\n",
      "24 Train loss: 0.0836266\n",
      "25 Train loss: 0.0744632\n",
      "25 Test accuracy: 0.9552\n",
      "26 Train loss: 0.0830995\n",
      "27 Train loss: 0.0828328\n",
      "28 Train loss: 0.0873375\n",
      "29 Train loss: 0.0759319\n",
      "30 Train loss: 0.0571478\n",
      "30 Test accuracy: 0.9635\n",
      "31 Train loss: 0.0604984\n",
      "32 Train loss: 0.0807575\n",
      "33 Train loss: 0.0696955\n",
      "34 Train loss: 0.0691861\n",
      "35 Train loss: 0.0520532\n",
      "35 Test accuracy: 0.9656\n",
      "36 Train loss: 0.0618176\n",
      "37 Train loss: 0.0473633\n",
      "38 Train loss: 0.0689642\n",
      "39 Train loss: 0.0559343\n",
      "40 Train loss: 0.0674646\n",
      "40 Test accuracy: 0.9668\n",
      "41 Train loss: 0.0646163\n",
      "42 Train loss: 0.0460741\n",
      "43 Train loss: 0.0650221\n",
      "44 Train loss: 0.0477211\n",
      "45 Train loss: 0.0471283\n",
      "45 Test accuracy: 0.9673\n",
      "46 Train loss: 0.0315943\n",
      "47 Train loss: 0.0366983\n",
      "48 Train loss: 0.0579268\n",
      "49 Train loss: 0.0417063\n",
      "50 Train loss: 0.0497452\n",
      "50 Test accuracy: 0.9689\n",
      "51 Train loss: 0.0537147\n",
      "52 Train loss: 0.0507989\n",
      "53 Train loss: 0.07915\n",
      "54 Train loss: 0.037005\n",
      "55 Train loss: 0.0379582\n",
      "55 Test accuracy: 0.9724\n",
      "56 Train loss: 0.042731\n",
      "57 Train loss: 0.0473236\n",
      "58 Train loss: 0.0537752\n",
      "59 Train loss: 0.0417022\n",
      "60 Train loss: 0.0438047\n",
      "60 Test accuracy: 0.9724\n",
      "61 Train loss: 0.0467484\n",
      "62 Train loss: 0.0293642\n",
      "63 Train loss: 0.0207704\n",
      "64 Train loss: 0.0518953\n",
      "65 Train loss: 0.044266\n",
      "65 Test accuracy: 0.9723\n",
      "66 Train loss: 0.0165285\n",
      "67 Train loss: 0.0452506\n",
      "68 Train loss: 0.0196215\n",
      "69 Train loss: 0.0325359\n",
      "70 Train loss: 0.0229821\n",
      "70 Test accuracy: 0.9743\n",
      "71 Train loss: 0.020623\n",
      "72 Train loss: 0.0579301\n",
      "73 Train loss: 0.0279319\n",
      "74 Train loss: 0.0194797\n",
      "75 Train loss: 0.04086\n",
      "75 Test accuracy: 0.9722\n",
      "76 Train loss: 0.0261779\n",
      "77 Train loss: 0.021407\n",
      "78 Train loss: 0.0187869\n",
      "79 Train loss: 0.0212785\n",
      "80 Train loss: 0.0204539\n",
      "80 Test accuracy: 0.9762\n",
      "81 Train loss: 0.0362233\n",
      "82 Train loss: 0.0157541\n",
      "83 Train loss: 0.023645\n",
      "84 Train loss: 0.0140412\n",
      "85 Train loss: 0.0201507\n",
      "85 Test accuracy: 0.9756\n",
      "86 Train loss: 0.0401293\n",
      "87 Train loss: 0.0166769\n",
      "88 Train loss: 0.0251853\n",
      "89 Train loss: 0.0210197\n",
      "90 Train loss: 0.0217886\n",
      "90 Test accuracy: 0.9758\n",
      "91 Train loss: 0.0115421\n",
      "92 Train loss: 0.0201638\n",
      "93 Train loss: 0.0259368\n",
      "94 Train loss: 0.0281382\n",
      "95 Train loss: 0.0142083\n",
      "95 Test accuracy: 0.9747\n",
      "96 Train loss: 0.0200869\n",
      "97 Train loss: 0.019502\n",
      "98 Train loss: 0.0172089\n",
      "99 Train loss: 0.0124171\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 500\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(len(X_train1) // batch_size):\n",
    "            X_batch, y_batch = generate_batch(X_train1, y_train1, batch_size)\n",
    "            loss_val, _ = sess.run([loss, training_op], feed_dict={X: X_batch, y: y_batch})\n",
    "        print(epoch, \"Train loss:\", loss_val)\n",
    "        if epoch % 5 == 0:\n",
    "            acc_test = accuracy.eval(feed_dict={X: X_test1, y: y_test1})\n",
    "            print(epoch, \"Test accuracy:\", acc_test)\n",
    "    save_path = saver.save(sess, \"./my_digit_comparison_model.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conseguimos 97% de acurácia na comparação entre dois dígitos. Nada mau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos congelar as comamadas ocultas da DNNA e utiliza-la para classificarmos todos os 10 digitos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 28*28\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_outputs = get_dnn_layers(X, name=\"DNN_A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "frozen_outputs = tf.stop_gradient(dnn_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = fully_connected(dnn_outputs, n_outputs, weights_initializer=he_init)\n",
    "Y_proba = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.MomentumOptimizer(learning_rate, momentum, use_nesterov=True)\n",
    "training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "dnn_A_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"DNN_A\")\n",
    "restore_saver = tf.train.Saver(var_list={var.op.name: var for var in dnn_A_vars})\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "agora podemos carregar os valores das variáveis do nosso modelo anteror em DNN_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_digit_comparison_model.ckpt\n",
      "0 Test accuracy: 0.9517\n",
      "10 Test accuracy: 0.9544\n",
      "20 Test accuracy: 0.9606\n",
      "30 Test accuracy: 0.9627\n",
      "40 Test accuracy: 0.961\n",
      "50 Test accuracy: 0.9606\n",
      "60 Test accuracy: 0.9601\n",
      "70 Test accuracy: 0.9595\n",
      "80 Test accuracy: 0.9589\n",
      "90 Test accuracy: 0.9605\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./my_digit_comparison_model.ckpt\")\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train2))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
    "            X_batch, y_batch = X_train2[rnd_indices], y_train2[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        if epoch % 10 == 0:\n",
    "            acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "            print(epoch, \"Test accuracy:\", acc_test)\n",
    "    \n",
    "    save_path = saver.save(sess, \"./my_mnist_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "96% de acurácia!\n",
    "Não é o melhor resultado que obtemos até agora para o mnist, mas vale lembrar que nesta fase estamos usando apenas 500 imagens por classe. Ou seja, conseguimos resultados muito bons com poucos exemplos por meio de transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
