{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos carregar o modelo que já temos treinado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "restore_saver = tf.train.import_meta_graph(\"./mnist-0-4-tf.model.meta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
    "loss = tf.get_default_graph().get_tensor_by_name(\"loss:0\")\n",
    "y_proba = tf.get_default_graph().get_tensor_by_name(\"y_proba:0\")\n",
    "logits = y_proba.op.inputs[0]\n",
    "accuracy = tf.get_default_graph().get_tensor_by_name(\"accuracy:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para que possamos congelar as camadas inferiores, vamos remocer suas variáveis da lista de variáveis treinávis (trainables) do otimizador, deixando apenas a camada saída ocmo treinável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "output_layer_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"logits\")\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, name=\"Adam2\")\n",
    "training_op = optimizer.minimize(loss, var_list=output_layer_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "five_frozen_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos treinar essa nova DNN em dígitos de 5 a 9 (usamos a mesma camada de saída pois ainda temos o mesmo formato, 5 dígitos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos carregar os dados, note que removemos 5 das labels porque o tensorflow espera inteiros de 0 a n_classes - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "train_data = mnist.train.images # Returns np.array\n",
    "train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "eval_data = mnist.test.images # Returns np.array\n",
    "eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    "\n",
    "X_valid, X_train = train_data[:5000], train_data[5000:]\n",
    "y_valid, y_train = train_labels[:5000], train_labels[5000:]\n",
    "\n",
    "X_train1 = X_train[y_train < 5]\n",
    "y_train1 = y_train[y_train < 5]\n",
    "X_valid1 = X_valid[y_valid < 5]\n",
    "y_valid1 = y_valid[y_valid < 5]\n",
    "X_test1 = eval_data[eval_labels < 5]\n",
    "y_test1 = eval_labels[eval_labels < 5]\n",
    "\n",
    "X_train2 = X_train[y_train >= 5]\n",
    "y_train2 = y_train[y_train >= 5] - 5\n",
    "X_valid2 = X_valid[y_valid >= 5]\n",
    "y_valid2 = y_valid[y_valid >= 5] - 5\n",
    "X_test2 = eval_data[eval_labels >= 5]\n",
    "y_test2 = eval_labels[eval_labels >= 5] - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 20\n",
    "\n",
    "max_checks_without_progress = 20\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./mnist-0-4-tf.model\n",
      "0\tValidation loss: 0.427162\tBest loss: 0.427162\tAccuracy: 86.32%\n",
      "1\tValidation loss: 0.357917\tBest loss: 0.357917\tAccuracy: 88.67%\n",
      "2\tValidation loss: 0.332957\tBest loss: 0.332957\tAccuracy: 89.49%\n",
      "3\tValidation loss: 0.323527\tBest loss: 0.323527\tAccuracy: 89.78%\n",
      "4\tValidation loss: 0.304531\tBest loss: 0.304531\tAccuracy: 90.48%\n",
      "5\tValidation loss: 0.295505\tBest loss: 0.295505\tAccuracy: 90.52%\n",
      "6\tValidation loss: 0.293611\tBest loss: 0.293611\tAccuracy: 90.44%\n",
      "7\tValidation loss: 0.295357\tBest loss: 0.293611\tAccuracy: 90.61%\n",
      "8\tValidation loss: 0.288027\tBest loss: 0.288027\tAccuracy: 90.98%\n",
      "9\tValidation loss: 0.289948\tBest loss: 0.288027\tAccuracy: 90.48%\n",
      "10\tValidation loss: 0.287404\tBest loss: 0.287404\tAccuracy: 90.73%\n",
      "11\tValidation loss: 0.289183\tBest loss: 0.287404\tAccuracy: 90.69%\n",
      "12\tValidation loss: 0.282972\tBest loss: 0.282972\tAccuracy: 90.77%\n",
      "13\tValidation loss: 0.283117\tBest loss: 0.282972\tAccuracy: 90.61%\n",
      "14\tValidation loss: 0.283567\tBest loss: 0.282972\tAccuracy: 90.85%\n",
      "15\tValidation loss: 0.277237\tBest loss: 0.277237\tAccuracy: 90.61%\n",
      "16\tValidation loss: 0.277240\tBest loss: 0.277237\tAccuracy: 91.10%\n",
      "17\tValidation loss: 0.283007\tBest loss: 0.277237\tAccuracy: 90.77%\n",
      "18\tValidation loss: 0.277301\tBest loss: 0.277237\tAccuracy: 90.89%\n",
      "19\tValidation loss: 0.277855\tBest loss: 0.277237\tAccuracy: 90.81%\n",
      "20\tValidation loss: 0.280748\tBest loss: 0.277237\tAccuracy: 91.02%\n",
      "21\tValidation loss: 0.278630\tBest loss: 0.277237\tAccuracy: 90.89%\n",
      "22\tValidation loss: 0.281111\tBest loss: 0.277237\tAccuracy: 90.77%\n",
      "23\tValidation loss: 0.278805\tBest loss: 0.277237\tAccuracy: 90.94%\n",
      "24\tValidation loss: 0.281260\tBest loss: 0.277237\tAccuracy: 90.77%\n",
      "25\tValidation loss: 0.273819\tBest loss: 0.273819\tAccuracy: 91.18%\n",
      "26\tValidation loss: 0.291245\tBest loss: 0.273819\tAccuracy: 90.36%\n",
      "27\tValidation loss: 0.278750\tBest loss: 0.273819\tAccuracy: 90.81%\n",
      "28\tValidation loss: 0.277709\tBest loss: 0.273819\tAccuracy: 91.06%\n",
      "29\tValidation loss: 0.281807\tBest loss: 0.273819\tAccuracy: 90.73%\n",
      "30\tValidation loss: 0.279556\tBest loss: 0.273819\tAccuracy: 90.81%\n",
      "31\tValidation loss: 0.275177\tBest loss: 0.273819\tAccuracy: 90.73%\n",
      "32\tValidation loss: 0.273010\tBest loss: 0.273010\tAccuracy: 91.06%\n",
      "33\tValidation loss: 0.279841\tBest loss: 0.273010\tAccuracy: 90.77%\n",
      "34\tValidation loss: 0.276322\tBest loss: 0.273010\tAccuracy: 90.65%\n",
      "35\tValidation loss: 0.291806\tBest loss: 0.273010\tAccuracy: 90.36%\n",
      "36\tValidation loss: 0.281372\tBest loss: 0.273010\tAccuracy: 90.40%\n",
      "37\tValidation loss: 0.278483\tBest loss: 0.273010\tAccuracy: 90.81%\n",
      "38\tValidation loss: 0.272076\tBest loss: 0.272076\tAccuracy: 90.94%\n",
      "39\tValidation loss: 0.272535\tBest loss: 0.272076\tAccuracy: 91.18%\n",
      "40\tValidation loss: 0.282390\tBest loss: 0.272076\tAccuracy: 90.65%\n",
      "41\tValidation loss: 0.276957\tBest loss: 0.272076\tAccuracy: 90.56%\n",
      "42\tValidation loss: 0.282127\tBest loss: 0.272076\tAccuracy: 90.81%\n",
      "43\tValidation loss: 0.274323\tBest loss: 0.272076\tAccuracy: 90.65%\n",
      "44\tValidation loss: 0.278648\tBest loss: 0.272076\tAccuracy: 90.98%\n",
      "45\tValidation loss: 0.284496\tBest loss: 0.272076\tAccuracy: 90.61%\n",
      "46\tValidation loss: 0.271499\tBest loss: 0.271499\tAccuracy: 91.26%\n",
      "47\tValidation loss: 0.279637\tBest loss: 0.271499\tAccuracy: 90.69%\n",
      "48\tValidation loss: 0.276318\tBest loss: 0.271499\tAccuracy: 90.56%\n",
      "49\tValidation loss: 0.282211\tBest loss: 0.271499\tAccuracy: 90.56%\n",
      "50\tValidation loss: 0.274616\tBest loss: 0.271499\tAccuracy: 91.18%\n",
      "51\tValidation loss: 0.278864\tBest loss: 0.271499\tAccuracy: 90.81%\n",
      "52\tValidation loss: 0.281308\tBest loss: 0.271499\tAccuracy: 90.61%\n",
      "53\tValidation loss: 0.277867\tBest loss: 0.271499\tAccuracy: 90.65%\n",
      "54\tValidation loss: 0.278419\tBest loss: 0.271499\tAccuracy: 90.98%\n",
      "55\tValidation loss: 0.273448\tBest loss: 0.271499\tAccuracy: 90.94%\n",
      "56\tValidation loss: 0.281049\tBest loss: 0.271499\tAccuracy: 90.94%\n",
      "57\tValidation loss: 0.275759\tBest loss: 0.271499\tAccuracy: 91.22%\n",
      "58\tValidation loss: 0.277512\tBest loss: 0.271499\tAccuracy: 90.98%\n",
      "59\tValidation loss: 0.272629\tBest loss: 0.271499\tAccuracy: 91.39%\n",
      "60\tValidation loss: 0.276472\tBest loss: 0.271499\tAccuracy: 90.73%\n",
      "61\tValidation loss: 0.272034\tBest loss: 0.271499\tAccuracy: 91.18%\n",
      "62\tValidation loss: 0.274900\tBest loss: 0.271499\tAccuracy: 91.02%\n",
      "63\tValidation loss: 0.275536\tBest loss: 0.271499\tAccuracy: 91.26%\n",
      "64\tValidation loss: 0.272298\tBest loss: 0.271499\tAccuracy: 91.26%\n",
      "65\tValidation loss: 0.284262\tBest loss: 0.271499\tAccuracy: 90.48%\n",
      "66\tValidation loss: 0.278025\tBest loss: 0.271499\tAccuracy: 90.85%\n",
      "Early stopping!\n",
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_5_to_9_five_frozen\n",
      "Final test accuracy: 91.24%\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./mnist-0-4-tf.model\")\n",
    "    for var in output_layer_vars:\n",
    "        var.initializer.run()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train2))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train2)//batch_size):\n",
    "            X_batch, y_batch = X_train2[rnd_indices], y_train2[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid2, y:y_valid2})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = five_frozen_saver.save(sess, \"./my_mnist_model_5_to_9_five_frozen\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    five_frozen_saver.restore(sess, \"./my_mnist_model_5_to_9_five_frozen\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste exemplo, a única camada treinável foi a a de saída, ou seja, utilizamos o conhecimento do modelo treinado em dígitos de 0 a 4 e ajustamos apenas uma camada para que ele pudesse aprender a reconhecer outros dígitos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos adicionar uma camada no topo da última camada oculta da rede e retreinar o modelo com uma nova softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import fully_connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_init = tf.contrib.layers.variance_scaling_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "n_outputs = 5\n",
    "restore_saver = tf.train.import_meta_graph(\"./mnist-0-4-tf.model.meta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden5_out = tf.get_default_graph().get_tensor_by_name(\"hidden5/Elu:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_6 = fully_connected(hidden5_out, 100, activation_fn=tf.nn.elu, \n",
    "                            weights_initializer=he_init, scope=\"hidden6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = fully_connected(hidden_6, 5, activation_fn=None, weights_initializer=he_init, \n",
    "                         scope=\"new_logits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_proba = tf.nn.softmax(logits)\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy)\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "output_layer_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"hidden6|new_logits\")\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, name=\"Adam2\")\n",
    "training_op = optimizer.minimize(loss, var_list=output_layer_vars)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "four_frozen_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 20\n",
    "\n",
    "max_checks_without_progress = 20\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./mnist-0-4-tf.model\n",
      "0\tValidation loss: 0.295949\tBest loss: 0.295949\tAccuracy: 90.77%\n",
      "1\tValidation loss: 0.259078\tBest loss: 0.259078\tAccuracy: 91.43%\n",
      "2\tValidation loss: 0.217295\tBest loss: 0.217295\tAccuracy: 92.46%\n",
      "3\tValidation loss: 0.224532\tBest loss: 0.217295\tAccuracy: 92.38%\n",
      "4\tValidation loss: 0.187246\tBest loss: 0.187246\tAccuracy: 93.41%\n",
      "5\tValidation loss: 0.178598\tBest loss: 0.178598\tAccuracy: 93.57%\n",
      "6\tValidation loss: 0.197313\tBest loss: 0.178598\tAccuracy: 93.00%\n",
      "7\tValidation loss: 0.181959\tBest loss: 0.178598\tAccuracy: 93.65%\n",
      "8\tValidation loss: 0.177878\tBest loss: 0.177878\tAccuracy: 93.90%\n",
      "9\tValidation loss: 0.163134\tBest loss: 0.163134\tAccuracy: 94.19%\n",
      "10\tValidation loss: 0.164856\tBest loss: 0.163134\tAccuracy: 94.56%\n",
      "11\tValidation loss: 0.186183\tBest loss: 0.163134\tAccuracy: 94.07%\n",
      "12\tValidation loss: 0.177134\tBest loss: 0.163134\tAccuracy: 93.57%\n",
      "13\tValidation loss: 0.151317\tBest loss: 0.151317\tAccuracy: 94.81%\n",
      "14\tValidation loss: 0.157875\tBest loss: 0.151317\tAccuracy: 94.19%\n",
      "15\tValidation loss: 0.167772\tBest loss: 0.151317\tAccuracy: 94.03%\n",
      "16\tValidation loss: 0.164502\tBest loss: 0.151317\tAccuracy: 94.11%\n",
      "17\tValidation loss: 0.158878\tBest loss: 0.151317\tAccuracy: 94.73%\n",
      "18\tValidation loss: 0.181872\tBest loss: 0.151317\tAccuracy: 94.15%\n",
      "19\tValidation loss: 0.161043\tBest loss: 0.151317\tAccuracy: 94.56%\n",
      "20\tValidation loss: 0.174005\tBest loss: 0.151317\tAccuracy: 94.27%\n",
      "21\tValidation loss: 0.152992\tBest loss: 0.151317\tAccuracy: 95.30%\n",
      "22\tValidation loss: 0.171208\tBest loss: 0.151317\tAccuracy: 94.40%\n",
      "23\tValidation loss: 0.164929\tBest loss: 0.151317\tAccuracy: 94.85%\n",
      "24\tValidation loss: 0.156266\tBest loss: 0.151317\tAccuracy: 95.22%\n",
      "25\tValidation loss: 0.150964\tBest loss: 0.150964\tAccuracy: 95.43%\n",
      "26\tValidation loss: 0.171138\tBest loss: 0.150964\tAccuracy: 94.48%\n",
      "27\tValidation loss: 0.167332\tBest loss: 0.150964\tAccuracy: 95.06%\n",
      "28\tValidation loss: 0.166743\tBest loss: 0.150964\tAccuracy: 95.18%\n",
      "29\tValidation loss: 0.162578\tBest loss: 0.150964\tAccuracy: 95.30%\n",
      "30\tValidation loss: 0.192457\tBest loss: 0.150964\tAccuracy: 94.15%\n",
      "31\tValidation loss: 0.174722\tBest loss: 0.150964\tAccuracy: 94.97%\n",
      "32\tValidation loss: 0.171811\tBest loss: 0.150964\tAccuracy: 95.14%\n",
      "33\tValidation loss: 0.154397\tBest loss: 0.150964\tAccuracy: 95.39%\n",
      "34\tValidation loss: 0.161218\tBest loss: 0.150964\tAccuracy: 95.30%\n",
      "35\tValidation loss: 0.161036\tBest loss: 0.150964\tAccuracy: 95.71%\n",
      "36\tValidation loss: 0.166084\tBest loss: 0.150964\tAccuracy: 95.51%\n",
      "37\tValidation loss: 0.161905\tBest loss: 0.150964\tAccuracy: 95.76%\n",
      "38\tValidation loss: 0.171363\tBest loss: 0.150964\tAccuracy: 95.51%\n",
      "39\tValidation loss: 0.183113\tBest loss: 0.150964\tAccuracy: 95.14%\n",
      "40\tValidation loss: 0.181822\tBest loss: 0.150964\tAccuracy: 94.77%\n",
      "41\tValidation loss: 0.169313\tBest loss: 0.150964\tAccuracy: 95.63%\n",
      "42\tValidation loss: 0.187033\tBest loss: 0.150964\tAccuracy: 94.97%\n",
      "43\tValidation loss: 0.176308\tBest loss: 0.150964\tAccuracy: 95.10%\n",
      "44\tValidation loss: 0.189532\tBest loss: 0.150964\tAccuracy: 95.22%\n",
      "45\tValidation loss: 0.176886\tBest loss: 0.150964\tAccuracy: 95.67%\n",
      "Early stopping!\n",
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_four_frozen\n",
      "Final test accuracy: 94.80%\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./mnist-0-4-tf.model\")\n",
    "    for var in output_layer_vars:\n",
    "        var.initializer.run()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train2))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train2)//batch_size):\n",
    "            X_batch, y_batch = X_train2[rnd_indices], y_train2[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid2, y:y_valid2})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = four_frozen_saver.save(sess, \"./my_mnist_model_four_frozen\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    four_frozen_saver.restore(sess, \"./my_mnist_model_four_frozen\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
