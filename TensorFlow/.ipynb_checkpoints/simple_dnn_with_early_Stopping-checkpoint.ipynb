{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import fully_connected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para facilitar a alteração da camada de ativação e inicialização em todas as camadas, vamos utilizar o arg_scope. \n",
    "Para implementarmos a inicialização de He devemos utilizar o variable_scaler_initializar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 28 * 28 # MNIST\n",
    "n_outputs = 5\n",
    "\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_init = tf.contrib.layers.variance_scaling_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dnn_layers(inputs, n_neurons):\n",
    "    with tf.name_scope(\"dnn\"):\n",
    "        for layer in range(5):\n",
    "            inputs = fully_connected(inputs, n_neurons, \n",
    "                                     activation_fn=tf.nn.elu,\n",
    "                                     weights_initializer=he_init,\n",
    "                                     scope=\"hidden%d\" % (layer+1))\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_outputs = get_dnn_layers(X, 100)\n",
    "logits = fully_connected(dnn_outputs, n_outputs, weights_initializer=he_init, activation_fn=None, scope=\"logits\")\n",
    "y_probs = tf.nn.softmax(logits, name=\"y_probs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>training with Adam</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(loss, name=\"training_op\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>carregando os daodos...</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "train_data = mnist.train.images # Returns np.array\n",
    "train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "eval_data = mnist.test.images # Returns np.array\n",
    "eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vamos criar um conjunto de validação para utilizarmos o early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = train_data[:5000], train_data[5000:]\n",
    "y_valid, y_train = train_labels[:5000], train_labels[5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como pede o exercício, vamos aprender a classificar apenas os digitos 0 a 4, o restante utilizaremos transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = X_train[y_train < 5]\n",
    "y_train1 = y_train[y_train < 5]\n",
    "X_valid1 = X_valid[y_valid < 5]\n",
    "y_valid1 = y_valid[y_valid < 5]\n",
    "X_test1 = eval_data[eval_labels < 5]\n",
    "y_test1 = eval_labels[eval_labels < 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos criar uma variável para armazenar nossa melhor loss e duas para identificarmos se houve melhora na loss surante o treinamento e por quantas épocas. Assim, podemos acompanhar a loss para realizarmos early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss = np.infty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_progress_epochs = 0\n",
    "max_no_progress_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.069976\tBest loss: 0.069976 \tAccuracy: 97.98%\n",
      "1\tValidation loss: 0.056824\tBest loss: 0.056824 \tAccuracy: 98.17%\n",
      "2\tValidation loss: 0.073308\tBest loss: 0.056824 \tAccuracy: 97.55%\n",
      "3\tValidation loss: 0.059612\tBest loss: 0.056824 \tAccuracy: 98.29%\n",
      "4\tValidation loss: 0.063374\tBest loss: 0.056824 \tAccuracy: 98.60%\n",
      "5\tValidation loss: 0.058810\tBest loss: 0.056824 \tAccuracy: 98.25%\n",
      "6\tValidation loss: 0.078917\tBest loss: 0.056824 \tAccuracy: 97.82%\n",
      "7\tValidation loss: 0.060298\tBest loss: 0.056824 \tAccuracy: 98.76%\n",
      "8\tValidation loss: 0.075487\tBest loss: 0.056824 \tAccuracy: 98.45%\n",
      "9\tValidation loss: 0.049872\tBest loss: 0.049872 \tAccuracy: 98.68%\n",
      "10\tValidation loss: 0.074699\tBest loss: 0.049872 \tAccuracy: 98.21%\n",
      "11\tValidation loss: 0.128505\tBest loss: 0.049872 \tAccuracy: 97.67%\n",
      "12\tValidation loss: 0.047868\tBest loss: 0.047868 \tAccuracy: 98.80%\n",
      "13\tValidation loss: 0.054819\tBest loss: 0.047868 \tAccuracy: 98.99%\n",
      "14\tValidation loss: 0.086944\tBest loss: 0.047868 \tAccuracy: 98.37%\n",
      "15\tValidation loss: 0.067162\tBest loss: 0.047868 \tAccuracy: 98.99%\n",
      "16\tValidation loss: 0.064729\tBest loss: 0.047868 \tAccuracy: 98.68%\n",
      "17\tValidation loss: 0.065082\tBest loss: 0.047868 \tAccuracy: 98.87%\n",
      "18\tValidation loss: 0.071744\tBest loss: 0.047868 \tAccuracy: 98.83%\n",
      "19\tValidation loss: 0.072530\tBest loss: 0.047868 \tAccuracy: 98.60%\n",
      "20\tValidation loss: 0.090636\tBest loss: 0.047868 \tAccuracy: 98.48%\n",
      "21\tValidation loss: 0.068158\tBest loss: 0.047868 \tAccuracy: 98.80%\n",
      "22\tValidation loss: 0.085161\tBest loss: 0.047868 \tAccuracy: 98.64%\n",
      "23\tValidation loss: 0.091377\tBest loss: 0.047868 \tAccuracy: 98.72%\n",
      "24\tValidation loss: 0.060379\tBest loss: 0.047868 \tAccuracy: 98.99%\n",
      "25\tValidation loss: 0.079127\tBest loss: 0.047868 \tAccuracy: 98.99%\n",
      "26\tValidation loss: 0.077495\tBest loss: 0.047868 \tAccuracy: 98.83%\n",
      "27\tValidation loss: 0.088556\tBest loss: 0.047868 \tAccuracy: 98.83%\n",
      "28\tValidation loss: 0.082846\tBest loss: 0.047868 \tAccuracy: 98.68%\n",
      "29\tValidation loss: 0.114112\tBest loss: 0.047868 \tAccuracy: 98.95%\n",
      "30\tValidation loss: 0.084331\tBest loss: 0.047868 \tAccuracy: 98.52%\n",
      "31\tValidation loss: 0.084632\tBest loss: 0.047868 \tAccuracy: 98.64%\n",
      "32\tValidation loss: 0.103755\tBest loss: 0.047868 \tAccuracy: 98.10%\n",
      "Early Stopping!\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train1))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train1)//batch_size):\n",
    "            X_batch, y_batch = X_train1[rnd_indices], y_train1[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid1, y: y_valid1})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = saver.save(sess, \"./my_mnist_model_0_to_4.ckpt\")\n",
    "            best_loss = loss_val\n",
    "            no_progress_epochs = 0\n",
    "        else:\n",
    "            no_progress_epochs += 1\n",
    "            if no_progress_epochs > max_no_progress_epochs:\n",
    "                print(\"Early Stopping!\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f} \\tAccuracy: {:.2f}%\".format(\n",
    "              epoch, loss_val, best_loss, acc_val*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_0_to_4.ckpt\n",
      "Final test accuracy: 99.16%\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_mnist_model_0_to_4.ckpt\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test1, y: y_test1})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
