{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos implementar um stacked autoencoder de fomra muito similar a uma MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import fully_connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reincia o grafo sempre para o mesmo estado\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs =28*28 #dimensoes do mnist\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 150\n",
    "n_hidden3 = n_hidden1\n",
    "n_outputs = n_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "l2_reg = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, n_inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.contrib.framework.arg_scope(\n",
    "        [fully_connected],\n",
    "        activation_fn = tf.nn.elu,\n",
    "        weights_initializer = tf.contrib.layers.variance_scaling_initializer(),\n",
    "        weights_regularizer = tf.contrib.layers.l2_regularizer(l2_reg)):\n",
    "    hidden1 = fully_connected(X, n_hidden1)\n",
    "    hidden2 = fully_connected(hidden1, n_hidden2)\n",
    "    hidden3 = fully_connected(hidden2, n_hidden3)\n",
    "    ouputs = fully_connected(hidden3, n_outputs, activation_fn=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos a MSE como loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_loss = tf.reduce_mean(tf.square(ouputs - X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e adicionamos a regularização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "loss = tf.add_n([reconstruction_loss] + reg_losses) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora podemos treinar nosso autoencoder. Note que as labels dos dígitos (y_batch) não são usadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 150\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.0772323\n",
      "loss:  0.055829\n",
      "loss:  0.0548687\n",
      "loss:  0.0550273\n",
      "loss:  0.0545416\n",
      "loss:  0.0545857\n",
      "loss:  0.0547076\n",
      "loss:  0.0549403\n",
      "loss:  0.0551446\n",
      "loss:  0.0546591\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        n_batches = mnist.train.num_examples // batch_size\n",
    "        for iteration in range(n_batches):            \n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch})\n",
    "        print('training loss: ', loss.eval(feed_dict={X: mnist.train.images}))\n",
    "    save_path = saver.save(sess, \"./my_mnist_autoencoder.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos enviar uma imagem para nosso autoencoder e ver como ele a reconstroi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = mnist.test.images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1284e1630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test_img.reshape(28, 28), cmap=\"binary\", interpolation=\"nearest\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_mnist_autoencoder.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_mnist_autoencoder.ckpt\")\n",
    "    reconstructed_img = ouputs.eval(feed_dict={X: [test_img]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwg+EIvxAKMIPhCL8QCjCD4T6HxHuQu+Y4cjaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1284e1e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(reconstructed_img.reshape(28, 28), cmap=\"binary\", interpolation=\"nearest\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
